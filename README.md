# AML_2019_Group30
Applied Machine Learning coursework (Group 30)


In machine learning gradient descent is used to update parameters of the chosen model, be it coefficients in Linear Regression of weights in Neural Networks. It is important because it updates all parameters simultaneously, it is an update rule in ML. The way gradient descent is done allows for distributing calculations across multiple processors or machines, which helps reduce time. 
What gradient descent does is it tunes parameters of the model to make sure loss function is minimized. Loss function is the function of the cost. Cost represents the sum of errors (difference between predicted and actual values) across all datapoints. So minimizing loss function by changing parameters helps for more accurate results in the output of machine learning task.  

Gradient descent is found using calculations of slopes of tangents (gradients) at every point of the plotted function starting from a specified point on a function curve. These points are the same step size away from each other on the whole function curve. Step size needs to be decided on. So gradient descent algorithm looks for a minimum point by stepping (by the step size) downhill until minimum is found. Minimum is allocated where the tangent with a steepest slope to the function curve is located. 
There is possibility here that minimum found will be local not global, meaning that gradient descent algorithm finds the wrong point and will not minimize the function as a result. Therefore changing starting points and number of iteration and comparing results for minimum could help greatly. So this process of stepping downhill and finding minimum tangents should be repeated a lot (10000 times in our case). 
It is also crucial to experiment with step sizes. If step size is too big, it could be that minimum will not be found, it will be skipped in the algorithm and minimum point found by gradient descent algorithm will not be accurate enough. If step size is too small, it might take up too much time and space on the computer, computational costs apply. It takes very long time to get to the bottom. Trade-off needs to be made sometimes. Also since step size depends on steepness of the slope, the steeper the slope is the larger the step sizeâ€™s absolute magnitude is.

For vanilla GD all samples in the data are used to determine the global minimum, whereas stochastic GD can be used on a subset of samples. This helps to lower  requirements for computer memory. When there are big number of dimensions  in dataset, it could be more suitable to use Stochastic GD instead of vanilla GD.  Stochastic GD often converges much faster that vanilla GD but is not as accurate as vanilla GD. 
Stochastic GD algorithm shuffles the points in which it measures gradients, randomization of the process reduces the risk of finding local minimum instead of global minimum. Global minimum is our aim, the minimum of the whole function, whereas local minimum is one of the multiple minimums the loss function has. For example function we used has three local minima, that is why it is called three hump camel function. 

Stochastic GD is better for larger datasets where smaller subsets of dataset could be used only to accurately find global minimum, whereas for plain vanilla GD algorithm it has to iterate through the whole dataset. Stochastic GD is quicker but it can be less accurate than plain vanilla GD. 

Momentum GD helps to accelerate the process, it might be more useful with more complicated functions, our function might be a little too simple for this method, therefore our results were not great here. Momentum GD moves in a way that reminds of pendulum movement, that is why this algorithm does not get stuck at one local minima, it allows for exploration of all local minima and exits them due to pendulum-like movements too. Number of iterations should be large here. 

Results comparison: 
Plain vanilla gradient descent algorithm showed same results as stochastic GD, momentum GD found better results that both vanilla and stochastic GD. This could be because vanilla got stuck in the local minimum point, as well as stochastic GD. We did not use sub-sample for stochastic GD calculations, it could be the reason why stochastic and vanilla GD showed same results. WE also tried to experiment with different starting points but could not attain same results as momentum GD for vanilla GD algorithm. Maybe if we experimented more we could, but this just shows that momentum GD is better GD algorithm for three hump camel function in our case. There were also experiments with number of iterations which did not show any exciting changes. For time of processing the output of code to decrease dramatically we used Colab platform. 
